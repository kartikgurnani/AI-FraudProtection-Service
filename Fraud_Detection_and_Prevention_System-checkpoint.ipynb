import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE  # For handling class imbalance

# Load the dataset
df = pd.read_csv("Fraud.csv")

# Basic data overview
print(df)

# Check for missing values
print(df.isnull().sum())

# Describe dataset statistics
print(df.describe())

# Select features and target variable
X = df[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]
y = df['isFraud']

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling: Standardize features for better model performance
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Handle class imbalance with SMOTE (Synthetic Minority Over-sampling Technique)
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)

# --- Logistic Regression Model ---

# Initialize Logistic Regression with class_weight to handle imbalance
logreg = LogisticRegression(class_weight='balanced', max_iter=1000)

# Fit the model on resampled data
logreg.fit(X_train_resampled, y_train_resampled)

# Predict on test data
y_pred_lr = logreg.predict(X_test_scaled)

# Evaluate Logistic Regression
accuracy_lr = accuracy_score(y_test, y_pred_lr)
precision_lr = precision_score(y_test, y_pred_lr)
recall_lr = recall_score(y_test, y_pred_lr)
f1_lr = f1_score(y_test, y_pred_lr)
roc_auc_lr = roc_auc_score(y_test, y_pred_lr)
conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)

# Output Logistic Regression results
print("Logistic Regression Performance:")
print(f"Accuracy: {accuracy_lr}")
print(f"Precision: {precision_lr}")
print(f"Recall: {recall_lr}")
print(f"F1 Score: {f1_lr}")
print(f"ROC AUC Score: {roc_auc_lr}")
print("Confusion Matrix:\n", conf_matrix_lr)

# --- Hyperparameter Tuning with GridSearchCV for Logistic Regression ---

param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],
    'solver': ['lbfgs', 'liblinear']
}

grid_search = GridSearchCV(LogisticRegression(class_weight='balanced', max_iter=1000), param_grid, scoring='roc_auc', cv=5)
grid_search.fit(X_train_resampled, y_train_resampled)

# Best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters for Logistic Regression:", best_params)

# Evaluate the best model
best_lr_model = grid_search.best_estimator_
y_pred_best_lr = best_lr_model.predict(X_test_scaled)

# Metrics for the tuned model
accuracy_best_lr = accuracy_score(y_test, y_pred_best_lr)
print("Tuned Logistic Regression Accuracy:", accuracy_best_lr)

# --- Random Forest Classifier ---

# Initialize Random Forest with class_weight to handle imbalance
rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)

# Fit the model
rf.fit(X_train, y_train)

# Predict on test data
y_pred_rf = rf.predict(X_test)

# Evaluate Random Forest
accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf)
roc_auc_rf = roc_auc_score(y_test, y_pred_rf)
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)

# Output Random Forest results
print("Random Forest Performance:")
print(f"Accuracy: {accuracy_rf}")
print(f"Precision: {precision_rf}")
print(f"Recall: {recall_rf}")
print(f"F1 Score: {f1_rf}")
print(f"ROC AUC Score: {roc_auc_rf}")
print("Confusion Matrix:\n", conf_matrix_rf)

# Optional: Hyperparameter tuning for Random Forest could be added similarly

# --- Visualization of Confusion Matrices ---

def plot_confusion_matrix(cm, title):
    plt.figure(figsize=(6,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(title)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.show()

plot_confusion_matrix(conf_matrix_lr, "Logistic Regression Confusion Matrix")
plot_confusion_matrix(conf_matrix_rf, "Random Forest Confusion Matrix")
